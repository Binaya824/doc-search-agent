# -*- coding: utf-8 -*-
"""pdf 2 docx.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hUCc_j-KqXiwc0r4RghPvd4lguJileh2
"""

# Install PyMuPDF
# !pip install pymupdf

# # Install Tesseract OCR and pytesseract
# !sudo apt install tesseract-ocr
# !pip install pytesseract

# # Install Pillow
# !pip install Pillow

# # Install Ghostscript and Camelot
# !sudo apt install ghostscript
# !pip install camelot-py[cv]

# # Install python-docx
# !pip install python-docx
# !pip install opencv-python

# from google.colab import drive
# drive.mount('/content/drive')

import fitz  # PyMuPDF for PDF extraction
# import pytesseract  # OCR for scanned PDFs
from PIL import Image , ImageOps # For handling images with Tesseract
# import camelot  # For table extraction
from docx import Document  # For generating Word documents
from io import BytesIO
from docx.shared import Pt , RGBColor  # For setting font size in points
from docx.enum.text import WD_ALIGN_PARAGRAPH  # For paragraph alignment
from docx.oxml.ns import qn  # For accessing custom XML for more advanced styling (optional)
from docx.shared import Pt
from docx.shared import Inches
from docx.oxml.ns import qn
from docx.oxml import OxmlElement
from io import BytesIO
from docx.oxml import parse_xml
from docx.oxml.ns import nsdecls
import json
import base64
# from IPython.display import display
import cv2
import numpy as np
import io


# Function to extract text and layout information from PDF using PyMuPDF
def extract_text_with_layout(page):
    page_text_data = []  # To store data for the current page
    blocks = page.get_text("dict")["blocks"]

    paragraphs = []  # To store paragraphs
    current_paragraph = []
    last_line_bottom = None  # Track the bottom y-coordinate of the previous line

    for block in blocks:
        if block['type'] == 0:  # Text block
            for line in block['lines']:  # Iterate over each line
                line_text = ""  # Concatenate span texts to form a full line
                line_bbox = [float('inf'), float('inf'), float('-inf'), float('-inf')]  # Initialize line bbox

                for span in line['spans']:
                    if 'text' in span and span['text'].strip():
                        line_text += span['text']  # Concatenate span text
                        # Expand line bbox to include span bbox
                        if span.get('bbox'):
                            line_bbox[0] = min(line_bbox[0], span['bbox'][0])
                            line_bbox[1] = min(line_bbox[1], span['bbox'][1])
                            line_bbox[2] = max(line_bbox[2], span['bbox'][2])
                            line_bbox[3] = max(line_bbox[3], span['bbox'][3])

                # Add line to the current paragraph
                if line_text.strip():
                    # Determine if this line is part of the current paragraph or a new paragraph
                    if last_line_bottom is not None:
                        line_spacing = line_bbox[1] - last_line_bottom
                        # Adjust threshold based on font size or fixed value
                        if line_spacing > 1.5 * span.get('size', 0):  # Threshold for new paragraph
                            # Save the current paragraph and start a new one
                            if current_paragraph:
                                paragraphs.append("\n".join(current_paragraph))
                                current_paragraph = []

                    # Add the current line to the paragraph
                    current_paragraph.append(line_text)
                    last_line_bottom = line_bbox[3]  # Update the last line bottom coordinate

    # Add any remaining paragraph
    if current_paragraph:
        paragraphs.append("\n".join(current_paragraph))

    return paragraphs

# Function to extract drawings (vector graphics) from PDF
def extract_drawings(page):
        # display(page)
    # doc = fitz.open(pdf_path)
    # drawings = []

    # # Iterate over each page to extract drawing commands
    # for page_num, page in enumerate(doc):
    #     print(f"Extracting drawings from page {page_num + 1}...")

    #     # Extract annotations and vector graphics
        page_drawings = []
        drawing_items = page.get_drawings()
        for drawing in drawing_items:

            bbox = drawing.get('rect', None)  # Use 'rect' as fallback for bounding box
            stroke_color = drawing.get('color', (0, 0, 0))  # Default to black if color is None
            fill_color = drawing.get('fill', (0, 0, 0))  # Default to black if fill color is None

            # Ensure bbox, stroke_color, and fill_color are iterable
            bbox = bbox if bbox else [0, 0, 0, 0]
            stroke_color = stroke_color if stroke_color else (0, 0, 0)
            fill_color = fill_color if fill_color else (0, 0, 0)

            if(drawing.get('items')[0][0] == 'l'):
              # print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Drawings ----------------->" ,  drawing)
              page_drawings.append({
                'bbox': list(bbox),  # Convert to list to ensure JSON compatibility
                'stroke_color': list(stroke_color),  # Convert to list
                'fill_color': list(fill_color),  # Convert to list
              })



        return page_drawings

        # Add extracted drawings to the list
    #     if page_drawings:
    #         drawings.append({
    #             'page_num': page_num + 1,
    #             'drawings': page_drawings,
    #         })

    # print(f"Extracted drawings from {len(drawings)} pages.{drawings}")
    # return drawings
def extract_drawings_cv2(page):
    # Get the pixmap (image) of the page
    pix = page.get_pixmap()
    # Convert the pixmap to PNG bytes
    img_bytes = pix.tobytes("png")

    # Convert bytes to a NumPy array
    nparr = np.frombuffer(img_bytes, np.uint8)
    # Decode the array into an image
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    # Display the image (optional, if running in a notebook)
    # display(Image(data=img_bytes))

    # Convert the image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Detect edges using Canny edge detection
    edges = cv2.Canny(gray, 50, 150)

    # Detect lines using Hough Line Transform
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength=50, maxLineGap=10)

    # If lines are found, print their coordinates
    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]
            # print(f"Line: Start=({x1}, {y1}), End=({x2}, {y2})")
    else:
        print("No lines detected")

# def extract_tables(pdf_path):
#     tables = camelot.read_pdf(pdf_path, pages='all', flavor='stream')  # Use flavor='lattice' for grid-based tables
#     return tables

# Function to extract images from PDF
def extract_images(page):
    """
    Extracts images from a given PDF page with their bounding boxes.

    Args:
        page: A PyMuPDF page object.

    Returns:
        List of dictionaries containing image data and their bounding boxes.
    """
    images_with_bbox = []

    # Get all images on the page
    image_list = page.get_images(full=True)

    for img_index, img in enumerate(image_list):
        xref = img[0]  # Image reference number
        base_image = page.parent.extract_image(xref)  # Extract image using parent document
        img_bytes = base_image["image"]
        img_ext = base_image["ext"]

        # Load image with PIL
        image = Image.open(io.BytesIO(img_bytes))

        # Handle Transparency Mask (SMask)
        # print(img_index , "image ====================== mode =======>>>>>" , image.mode)
        image_2 = image.convert("RGB")
        img= ImageOps.invert(image_2)
        # print("img 2 ))))))))))))))))))))))))))))))))))))))))))))" , img)
        # display(image_2)
        mask_bytes = base_image.get("smask") or base_image.get("mask")
        if isinstance(mask_bytes, bytes):  # Ensure mask is valid
            mask = Image.open(io.BytesIO(mask_bytes)).convert("L")  # Convert to grayscale
            mask = ImageOps.invert(mask)  # Fix inverted transparency
            image.putalpha(mask)  # Apply corrected mask

        # Convert to RGB if necessary
        if image.mode in ["RGBA", "LA"]:
            background = Image.new("RGB", image.size, (255, 255, 255))
            background.paste(image, mask=image.split()[-1])  # Paste with mask
            image = background

        # Convert image to bytes for base64 encoding
        img_byte_arr = io.BytesIO()
        image.save(img_byte_arr, format=img_ext.upper())
        img_bytes = img_byte_arr.getvalue()

        # Get bounding box
        img_rects = page.get_image_rects(xref)
        for rect_index, rect in enumerate(img_rects):
            bbox = [rect.x0, rect.y0, rect.x1, rect.y1]
            data_uri = f"data:image/{img_ext};base64,{base64.b64encode(img_bytes).decode('utf-8')}"

            images_with_bbox.append({
                "base64_string": data_uri,
                "bbox": bbox,
                "image_index": img_index + 1,
            })

            # Save the image to a file
            image_filename = f"page_img_{img_index + 1}.{img_ext}"
            image.save(image_filename)
            print(f"âœ… Saved image to {image_filename} with bbox: {bbox}")

    return images_with_bbox


# Function to extract tables from PDF using Camelot
# def extract_tables(pdf_path , page_no):
#     tables = camelot.read_pdf(pdf_path, pages=str(page_no), flavor='lattice')  # Use flavor='lattice' for grid-based tables
#     return tables


# Function to perform OCR on scanned PDF pages
def ocr_from_image(image_path):
    img = Image.open(image_path)
    text = pytesseract.image_to_string(img)
    return text

def filter_text_outside_tables(text_data, table_bboxes):
    """
    Filters text data to exclude entries that overlap with table bounding boxes.

    :param text_data: List of text data with bounding boxes.
    :param table_bboxes: List of table bounding boxes [(x1, y1, x2, y2), ...].
    :return: Filtered list of text data.
    """
    def is_inside_table(text_bbox, table_bbox):
        """
        Check if a text bounding box overlaps with a table bounding box.
        """
        return not (
            text_bbox[2] < table_bbox[0] or  # Text right < Table left
            text_bbox[0] > table_bbox[2] or  # Text left > Table right
            text_bbox[3] < table_bbox[1] or  # Text bottom < Table top
            text_bbox[1] > table_bbox[3]    # Text top > Table bottom
        )

    filtered_text = []
    for text_entry in text_data:
        text_bbox = text_entry['bbox']
        # Check if text bbox overlaps with any table bbox
        if not any(is_inside_table(text_bbox, table_bbox) for table_bbox in table_bboxes):
            filtered_text.append(text_entry)
        else:
            print(f"Excluding text inside table bbox: {text_entry['data']}")

    return filtered_text


# Function to generate Word document from extracted data
def create_word_document(text_data , images, drawings):
    doc = Document()

    # Iterate over pages in text_data
    for page_index, page_entries in enumerate(text_data):
        print(f"Processing page {page_index + 1}...")
        page_left_position = min(entry['bbox'][0] for entry in page_entries)

        # Extract tables for the current page
        tables = extract_tables(pdf_path, page_index + 1)
        table_bboxes = []
        table_data = []

        for table in tables:
            table_bboxes.append(table._bbox)  # Assuming table._bbox gives the bounding box (x1, y1, x2, y2)
            table_data.append({
                'data': table.df.values.tolist(),  # Extract table as a list of lists
                'bbox': table._bbox,
                'type': 'table'
            })

        filtered_text_data = filter_text_outside_tables(page_entries, table_bboxes)

        # print(";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; filtered text" , filtered_text_data)

        # Prepare text data with bounding boxes and type
        lines = []
        vertical_tolerance = 5

        for entry in filtered_text_data:
            added_to_line = False
            for line in lines:
                if abs(entry['bbox'][1] - line[0]['bbox'][1]) <= vertical_tolerance:
                    line.append(entry)
                    added_to_line = True
                    break
            if not added_to_line:
                lines.append([entry])

        text_data_with_bboxes = []
        for line_entries in lines:
            text_data_with_bboxes.append({
                'data': line_entries,
                'bbox': get_line_bbox(line_entries),
                'type': 'text'
            })

        # print("&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& text data"  , text_data_with_bboxes)
        # print("^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ table bboxes" , table_bboxes)
        # Combine text and table data and sort by vertical position (top)
        combined_content = text_data_with_bboxes + table_data
        combined_content.sort(key=lambda item: item['bbox'][1])  # Sort by the top (y1) of the bounding box
        for data in combined_content:
          pass
          # print("************************************************************************************************* data" , data)

        # Add content to the Word document
        for item in combined_content:
            if item['type'] == 'table':
                # Add table to the document
                table_content = item['data']
                num_columns = len(table_content[0])
                word_table = doc.add_table(rows=1, cols=num_columns)

                # Add header row
                hdr_cells = word_table.rows[0].cells
                for col_index, cell_text in enumerate(table_content[0]):  # Assuming first row is the header
                    hdr_cells[col_index].text = str(cell_text)

                # Add remaining rows
                for row in table_content[1:]:
                    row_cells = word_table.add_row().cells
                    for col_index, cell_text in enumerate(row):
                        row_cells[col_index].text = str(cell_text)

                doc.add_paragraph()  # Add spacing after the table

            elif item['type'] == 'text':
                # Check if the text overlaps with any table bounding box
                # overlaps_with_table = any(
                #     not (
                #         item['bbox'][0] < table_bbox[0] and # Text right < Table left
                #         item['bbox'][1] > table_bbox[1] and  # Text left > Table right
                #         item['bbox'][2] < table_bbox[2] or  # Text bottom < Table top
                #         item['bbox'][1] > table_bbox[3]    # Text top > Table bottom
                #     )
                #     for table_bbox in table_bboxes
                # )
                # if overlaps_with_table:
                #     continue

                # Add text as a paragraph
                paragraph = doc.add_paragraph()
                line_left_indent = item['data'][0]['bbox'][0]

                # Add indentation if necessary
                if line_left_indent > page_left_position:
                    indent = line_left_indent / 72  # Convert bbox[0] to points
                    paragraph.paragraph_format.left_indent = Inches(indent / 2)

                # Add text with styling
                for entry in item['data']:
                    run = paragraph.add_run(entry['text'])
                    run.font.name = entry['font']
                    run.font.size = Pt(entry['size'])
                    run.font.color.rgb = RGBColor(entry['color'][0], entry['color'][1], entry['color'][2])

                    # Add spaces based on the distance between the current and previous text
                    if len(paragraph.runs) > 1:
                        prev_entry = item['data'][item['data'].index(entry) - 1]
                        space_width = (entry['bbox'][0] - prev_entry['bbox'][2]) / 28.346  # Convert points to cm
                        paragraph.runs[-2].add_text(' ' * int(space_width * 5))  # Adjust multiplier for spacing

    # Save the document
    output_path = "/content/output_with_bbox.docx"
    doc.save(output_path)
    print(f"Word document with positions saved as {output_path}")


def get_line_bbox(line):
    """Helper function to calculate the bounding box for a line of text."""
    x1 = min(entry['bbox'][0] for entry in line)
    y1 = min(entry['bbox'][1] for entry in line)
    x2 = max(entry['bbox'][2] for entry in line)
    y2 = max(entry['bbox'][3] for entry in line)
    return [x1, y1, x2, y2]

def rgb_to_hex(rgb):
    """Convert an RGB tuple (r, g, b) to a hex color string."""
    return f'#{int(rgb[0] * 255):02x}{int(rgb[1] * 255):02x}{int(rgb[2] * 255):02x}'

def add_drawing(doc, drawing):
    """
    Adds a rectangle (bounding box) shape to the Word document.
    bbox: A list containing [x0, y0, x1, y1] coordinates of the bounding box.
    """

    if not drawing['bbox']:
        print("Invalid bounding box. Skipping drawing.")
        return

    x0, y0, x1, y1 = drawing['bbox']
    width = x1 - x0
    height = y1 - y0
    # Create a new paragraph to anchor the shape
    stroke_color = drawing.get('stroke_color', (1.0, 1.0, 1.0)) or (1.0, 1.0, 1.0)  # Default stroke (outline) color to black
    fill_color = drawing.get('fill_color', (1.0, 1.0, 1.0)) or (1.0, 1.0, 1.0)  # Default fill (background) color to white

    # print("stroke_color: " , stroke_color , "fill_color: " , fill_color)
    # Convert RGB to hex string
    if isinstance(fill_color, tuple):
        fill_color = rgb_to_hex(fill_color)
    if isinstance(stroke_color, tuple):
        stroke_color = rgb_to_hex(stroke_color)

    paragraph = doc.add_paragraph()
    # paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT

    # Create a custom XML element for the bounding box
     # Create a custom XML element for the bounding box
    # shape_element = OxmlElement('w:shapetype')
    # shape_element.set('id', 'rect')  # Unique shape identifier
    # shape_element.set('coordsize', f'{width},{height}')  # Size of shape
    # shape_element.set('style', f'position:absolute;left:{x0}pt;top:{y0}pt;width:{width}pt;height:{height}pt')

    # # Add a rectangle as a shape
    # rect = OxmlElement('w:shape')
    # rect.set('type', '#rect')
    # rect.set('style', f'position:absolute;left:{x0}pt;top:{y0}pt;width:{width}pt;height:{height}pt;')

    # # Set color for stroke (outline) and fill (background)
    # rect.set('stroke', stroke_color)
    # rect.set('fill', fill_color)

    # # Append rectangle to shape element and paragraph
    # shape_element.append(rect)
    # paragraph._element.append(shape_element)

    run = paragraph.add_run()

    # Create a shape in the document using an inline image placeholder
    shape = OxmlElement('w:shape')
    shape.set('id', 'drawing_rect')  # Shape identifier
    shape.set('style', f'width:{width}pt;height:{height}pt;position:absolute;')
    shape.set('strokecolor', stroke_color)  # Default stroke color: black
    shape.set('fillcolor', fill_color)  # Default fill color: white
    shape.set('strokeweight', '2pt')  # Thickness of the border

    # print("shape : ==============>" , shape)

    # Append the shape element to the paragraph's XML structure
    run._element.append(shape)


# Main conversion function
def convert_pdf_to_word(pdf_path):

   doc = fitz.open(pdf_path)
   data = []

   for page_number, page in enumerate(doc, start=1):

        # Step 1: Extract text and layout data from PDF
        text_data = extract_text_with_layout(page)
        print ("$$$$$$$$$$$$$$$$$$$ text data" , text_data)

        # print("extracted text data from convert_pdf_to_word ))))))))))))))))))))))))))))))))))))))))))))", text_data)
#         drawings = extract_drawings(page)

#         # Step 2: Extract tables from PDF (currently commented out)
#         # tables = extract_tables(pdf_path)

#         # Step 3: Extract images from PDF
#         images = extract_images(page)
#         extract_drawings_cv2(page)

#         data.append({
#             "text_data": text_data,
#             "drawings": drawings,
#             "images": images,
#             "page" : page_number
#         })

#    json_data = json.dumps(data, ensure_ascii=False, indent=4)
#    print(json_data)

      # print("%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% iamges" , images)

      # tables = extract_tables(pdf_path)
      # print("extracted tables from convert_pdf_to_word ))))))))))))))))))))))))))))))))))))))))))))", tables)

      # Step 4: Check if OCR is needed (scanned PDFs)
      # For OCR, we can apply OCR to images if the PDF is scanned
      # In this case, we'll assume that if there are images, we may need to OCR them
      # if images:
      #     ocr_texts = []
      #     for img in images:
      #         img_stream = io.BytesIO(img['image_bytes'])
      #         text = ocr_from_image(img_stream)
      #         ocr_texts.append(text)
      #     # Optionally, combine OCR text with extracted text_data if needed
      #     print(f"OCR Results: {ocr_texts}")

      # Step 5: Generate Word document
      # create_word_document(text_data, images , drawings)
      # print("Word document generated successfully!")


# Example usage
pdf_path = './User Guide Manual_ Document Upload and Processing System.pdf'  # Path to your PDF file
convert_pdf_to_word(pdf_path)